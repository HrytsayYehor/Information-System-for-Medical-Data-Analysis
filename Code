import faiss
import numpy as np
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer


# Ініціалізація моделі T5
def load_t5_model(model_name):
    print("Завантаження моделі T5...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return model, tokenizer


# Завантаження моделі T5
model_name = "t5-base"  # Використовуємо більш велику модель
model, tokenizer = load_t5_model(model_name)

# Завантаження моделі SentenceTransformer для векторизації
embedding_model = SentenceTransformer('all-MiniLM-L6-v2')

# Синтетичні медичні документи
documents = [
    "Пацієнт P001 - Іванов Іван Іванович, 45 років. Діагноз: Гіпертонія. Лікування: Призначено антигіпертензивні препарати.",
    "Пацієнт P002 - Петренко Петро Петрович, 60 років. Діагноз: Ішемічна хвороба серця. Лікування: Коронарна ангіопластика."
]

# Векторизація документів для FAISS
document_embeddings = embedding_model.encode(documents)
dimension = document_embeddings.shape[1]

# Ініціалізація індексу FAISS
index = faiss.IndexFlatL2(dimension)
index.add(np.array(document_embeddings))


# Пошук документів
def search_documents(query):
    query_embedding = embedding_model.encode([squery])
    _, indices = index.search(np.array(query_embedding), k=1)
    return documents[indices[0][0]]


# Генерація відповіді за допомогою T5
def generate_answer(prompt):
    inputs = tokenizer(prompt, return_tensors="pt", padding=True, truncation=True, max_length=512)
    inputs = inputs.to(model.device)
    outputs = model.generate(
        inputs['input_ids'],
        attention_mask=inputs['attention_mask'],
        max_new_tokens=100,
        num_return_sequences=1,
        no_repeat_ngram_size=2,
        temperature=0.7,
        top_p=0.9,
        top_k=50,
        repetition_penalty=1.2,  # Добавляем штраф за повторение
        length_penalty=1.0,  # Добавляем штраф за длину
        do_sample=True
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)


# Основна логіка RAG-системи
def rag_system(query):
    # 1. Пошук релевантного документа
    relevant_document = search_documents(query)
    print(f"Знайдений документ: {relevant_document}")

    # 2. Генерація відповіді T5
    prompt = f"Документ: {relevant_document}\nЗапит: {query}\nВідповідь:"
    answer = generate_answer(prompt)
    return answer

# Приклад запиту
query = "Які діагнози мають пацієнти?"
answer = rag_system(query)
print(f"Відповідь: {answer}")
